{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4a9fcb6",
   "metadata": {},
   "source": [
    "# Classic Neural Matrix Factorization (NeuMF) Training Pipeline\n",
    "\n",
    "1. First train a Generalized Matrix Factorization (GMF) model\n",
    "2. Then train a Multi-Layer Perceptron (MLP) model\n",
    "3. Finally fuse these models together and fine-tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a55d9f3",
   "metadata": {},
   "source": [
    "## Setup Environment and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7f790cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import Callable, Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import gc\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Check device availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b84e69",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87495ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data\"\n",
    "\n",
    "def read_data_df() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Reads in data and splits it into training and validation sets with a 75/25 split.\"\"\"\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, \"train_ratings.csv\"))\n",
    "\n",
    "    # Split sid_pid into sid and pid columns\n",
    "    df[[\"sid\", \"pid\"]] = df[\"sid_pid\"].str.split(\"_\", expand=True)\n",
    "    df = df.drop(\"sid_pid\", axis=1)\n",
    "    df[\"sid\"] = df[\"sid\"].astype(int)\n",
    "    df[\"pid\"] = df[\"pid\"].astype(int)\n",
    "    \n",
    "    # Split into train and validation dataset\n",
    "    train_df, valid_df = train_test_split(df, test_size=0.25)\n",
    "    return train_df, valid_df\n",
    "\n",
    "def evaluate(valid_df: pd.DataFrame, pred_fn: Callable[[np.ndarray, np.ndarray], np.ndarray]) -> float:\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        valid_df: Validation data, returned from read_data_df for example.\n",
    "        pred_fn: Function that takes in arrays of sid and pid and outputs their rating predictions.\n",
    "\n",
    "    Outputs: Validation RMSE\n",
    "    \"\"\"\n",
    "    \n",
    "    preds = pred_fn(valid_df[\"sid\"].values, valid_df[\"pid\"].values)\n",
    "    return root_mean_squared_error(valid_df[\"rating\"].values, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79027949",
   "metadata": {},
   "source": [
    "## Dataset class for PyTorch's DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65251e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.sids = df['sid'].values.astype(np.int64)\n",
    "        self.pids = df['pid'].values.astype(np.int64)\n",
    "        self.ratings = df['rating'].values.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sids[idx], self.pids[idx], self.ratings[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d8aa6e",
   "metadata": {},
   "source": [
    "## Model architectures and training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fdee556",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        self.output_layer = nn.Linear(embedding_dim, 1)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        \n",
    "        # Initialize weights\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
    "        nn.init.zeros_(self.user_bias.weight)\n",
    "        nn.init.zeros_(self.item_bias.weight)\n",
    "        nn.init.kaiming_uniform_(self.output_layer.weight)\n",
    "        \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embed = self.user_embedding(user_indices)\n",
    "        item_embed = self.item_embedding(item_indices)\n",
    "        element_product = user_embed * item_embed\n",
    "        \n",
    "        prediction = self.output_layer(element_product).squeeze()\n",
    "        prediction += self.user_bias(user_indices).squeeze()\n",
    "        prediction += self.item_bias(item_indices).squeeze()\n",
    "        \n",
    "        return torch.clamp(prediction, 1.0, 5.0)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, \n",
    "                 layers=[128, 64, 32], dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        # MLP layers\n",
    "        self.mlp_layers = []\n",
    "        layer_sizes = [embedding_dim * 2] + layers\n",
    "        \n",
    "        mlp_modules = []\n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            mlp_modules.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
    "            mlp_modules.append(nn.BatchNorm1d(layer_sizes[i+1]))\n",
    "            mlp_modules.append(nn.LeakyReLU(0.1))\n",
    "            mlp_modules.append(nn.Dropout(dropout))\n",
    "            \n",
    "        self.mlp_layers = nn.Sequential(*mlp_modules)\n",
    "        self.output_layer = nn.Linear(layer_sizes[-1], 1)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        \n",
    "        # Initialize weights\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
    "        nn.init.zeros_(self.user_bias.weight)\n",
    "        nn.init.zeros_(self.item_bias.weight)\n",
    "        \n",
    "        for m in self.mlp_layers:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.kaiming_uniform_(self.output_layer.weight)\n",
    "        \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embed = self.user_embedding(user_indices)\n",
    "        item_embed = self.item_embedding(item_indices)\n",
    "        \n",
    "        vector = torch.cat([user_embed, item_embed], dim=-1)\n",
    "        mlp_output = self.mlp_layers(vector)\n",
    "        \n",
    "        prediction = self.output_layer(mlp_output).squeeze()\n",
    "        prediction += self.user_bias(user_indices).squeeze()\n",
    "        prediction += self.item_bias(item_indices).squeeze()\n",
    "        \n",
    "        return torch.clamp(prediction, 1.0, 5.0)\n",
    "    \n",
    "class NeuMFPretrainedFusion(nn.Module):\n",
    "    def __init__(self, gmf_model, mlp_model, alpha=0.5):\n",
    "        super().__init__()\n",
    "        # GMF embeddings and output layers (copied from pretrained)\n",
    "        self.gmf_user_embedding = gmf_model.user_embedding\n",
    "        self.gmf_item_embedding = gmf_model.item_embedding\n",
    "        self.gmf_output = gmf_model.output_layer\n",
    "        \n",
    "        # MLP embeddings and layers (copied from pretrained)\n",
    "        self.mlp_user_embedding = mlp_model.user_embedding\n",
    "        self.mlp_item_embedding = mlp_model.item_embedding\n",
    "        self.mlp_layers = mlp_model.mlp_layers\n",
    "        self.mlp_output = mlp_model.output_layer\n",
    "        \n",
    "        # Bias terms\n",
    "        self.user_bias = gmf_model.user_bias\n",
    "        self.item_bias = gmf_model.item_bias\n",
    "        \n",
    "        # Fusion parameter (trainable or fixed)\n",
    "        self.alpha = nn.Parameter(torch.tensor(alpha)) if isinstance(alpha, float) else alpha\n",
    "        \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        # GMF path\n",
    "        gmf_user_embed = self.gmf_user_embedding(user_indices)\n",
    "        gmf_item_embed = self.gmf_item_embedding(item_indices)\n",
    "        gmf_vector = gmf_user_embed * gmf_item_embed\n",
    "        gmf_pred = self.gmf_output(gmf_vector)\n",
    "        \n",
    "        # MLP path\n",
    "        mlp_user_embed = self.mlp_user_embedding(user_indices)\n",
    "        mlp_item_embed = self.mlp_item_embedding(item_indices)\n",
    "        mlp_vector = torch.cat([mlp_user_embed, mlp_item_embed], dim=-1)\n",
    "        mlp_vector = self.mlp_layers(mlp_vector)\n",
    "        mlp_pred = self.mlp_output(mlp_vector)\n",
    "        \n",
    "        # Combine predictions with alpha weighting\n",
    "        prediction = self.alpha * gmf_pred + (1 - self.alpha) * mlp_pred\n",
    "        prediction = prediction.squeeze()\n",
    "        \n",
    "        # Add bias terms\n",
    "        prediction += self.user_bias(user_indices).squeeze()\n",
    "        prediction += self.item_bias(item_indices).squeeze()\n",
    "        \n",
    "        return torch.clamp(prediction, 1.0, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fde47373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_enhanced(model, train_df, valid_df, loader, optimizer, criterion, device, \n",
    "                  epochs=20, patience=5, clip_norm=1.0):\n",
    "    best_rmse = float('inf')\n",
    "    early_stop_counter = 0\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        # Training step\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for sids, pids, ratings in loader:\n",
    "            sids, pids, ratings = sids.to(device), pids.to(device), ratings.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(sids, pids)\n",
    "            loss = criterion(preds, ratings)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_norm)\n",
    "            \n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * len(ratings)\n",
    "            \n",
    "        # Create prediction function for evaluation\n",
    "        def pred_fn(s, p):\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                preds = model(\n",
    "                    torch.from_numpy(s).to(device), \n",
    "                    torch.from_numpy(p).to(device)\n",
    "                ).detach().cpu().numpy()\n",
    "            return np.clip(preds, 1, 5)\n",
    "        \n",
    "        # Evaluate on both train and validation sets\n",
    "        train_rmse = evaluate(train_df, pred_fn)\n",
    "        valid_rmse = evaluate(valid_df, pred_fn)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(valid_rmse)\n",
    "        \n",
    "        print(f\"Epoch {epoch:02d} — Train RMSE: {train_rmse:.4f}, Valid RMSE: {valid_rmse:.4f}, \"\n",
    "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        if valid_rmse < best_rmse:\n",
    "            best_rmse = valid_rmse\n",
    "            early_stop_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_ncf.pth')\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            \n",
    "        # Early stopping\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch} epochs\")\n",
    "            break\n",
    "    \n",
    "    print(f\"\\nBest Val RMSE: {best_rmse:.4f}\")\n",
    "    return best_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ee560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classic_ncf(num_users, num_items, train_loader, \n",
    "                      train_df, valid_df, device, criterion):\n",
    "    print(\"Step 1: Training GMF model...\")\n",
    "    gmf_model = GMF(num_users, num_items, embedding_dim=32).to(device)\n",
    "    gmf_optimizer = torch.optim.Adam(gmf_model.parameters(), lr=1e-3)\n",
    "    \n",
    "    train_enhanced(\n",
    "        model=gmf_model,\n",
    "        train_df=train_df,\n",
    "        valid_df=valid_df,\n",
    "        loader=train_loader,\n",
    "        optimizer=gmf_optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        epochs=20,\n",
    "        patience=3\n",
    "    )\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"\\nStep 2: Training MLP model...\")\n",
    "    mlp_model = MLP(num_users, num_items, embedding_dim=32, layers=[64, 32, 16]).to(device)\n",
    "    mlp_optimizer = torch.optim.Adam(mlp_model.parameters(), lr=1e-3)\n",
    "    \n",
    "    train_enhanced(\n",
    "        model=mlp_model,\n",
    "        train_df=train_df,\n",
    "        valid_df=valid_df,\n",
    "        loader=train_loader,\n",
    "        optimizer=mlp_optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        epochs=20,\n",
    "        patience=3\n",
    "    )\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Try different alpha values or make it learnable\n",
    "    print(\"\\nStep 3: Fine-tuning combined model...\")\n",
    "    best_alpha = 0.5\n",
    "    best_rmse = float('inf')\n",
    "    \n",
    "    # Option 1: Grid search alpha\n",
    "    for alpha in [0.3, 0.5, 0.7]:\n",
    "        print(f\"Testing alpha = {alpha}\")\n",
    "        fusion_model = NeuMFPretrainedFusion(\n",
    "            gmf_model, mlp_model, alpha=alpha).to(device)\n",
    "        \n",
    "        # Freeze embedding weights and only train output layers \n",
    "        for param in fusion_model.gmf_user_embedding.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in fusion_model.gmf_item_embedding.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in fusion_model.mlp_user_embedding.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in fusion_model.mlp_item_embedding.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        fusion_optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, fusion_model.parameters()), \n",
    "            lr=5e-4)\n",
    "        \n",
    "        rmse = train_enhanced(\n",
    "            model=fusion_model,\n",
    "            train_df=train_df,\n",
    "            valid_df=valid_df,\n",
    "            loader=train_loader,\n",
    "            optimizer=fusion_optimizer,\n",
    "            criterion=criterion,\n",
    "            device=device,\n",
    "            epochs=10,\n",
    "            patience=3\n",
    "        )\n",
    "        \n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_alpha = alpha\n",
    "    \n",
    "    # Option 2: Learnable alpha\n",
    "    print(\"\\nFinal model with learnable alpha...\")\n",
    "    fusion_model = NeuMFPretrainedFusion(\n",
    "        gmf_model, mlp_model, alpha=best_alpha).to(device)\n",
    "    \n",
    "    # Unfreeze everything for final training\n",
    "    fusion_optimizer = torch.optim.Adam(fusion_model.parameters(), lr=1e-4)\n",
    "    \n",
    "    final_rmse = train_enhanced(\n",
    "        model=fusion_model,\n",
    "        train_df=train_df,\n",
    "        valid_df=valid_df,\n",
    "        loader=train_loader,\n",
    "        optimizer=fusion_optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        epochs=15,\n",
    "        patience=5\n",
    "    )\n",
    "    \n",
    "    return fusion_model, final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b5ae1",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data\n",
    "\n",
    "Now let's load the training and validation data, preprocess it, and prepare the data loaders for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be4db33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 846140 rows, Validation set: 282047 rows\n",
      "Sample of training data:\n",
      "         rating   sid  pid\n",
      "1039945       3  9135  892\n",
      "185105        4  1564  291\n",
      "888332        5  7733  340\n",
      "866358        4  7529  407\n",
      "44674         4   368  308\n",
      "Global mean rating: 3.8179\n",
      "Num users: 10000, Num items: 1000\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_df, valid_df = read_data_df()\n",
    "print(f\"Train set: {len(train_df)} rows, Validation set: {len(valid_df)} rows\")\n",
    "print(f\"Sample of training data:\\n{train_df.head()}\")\n",
    "\n",
    "# Apply preprocessing\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Apply user-specific normalization to ratings\"\"\"\n",
    "    # Get global mean\n",
    "    global_mean = df['rating'].mean()\n",
    "    print(f\"Global mean rating: {global_mean:.4f}\")\n",
    "    \n",
    "    # Get user biases (average rating deviation from global mean)\n",
    "    user_biases = df.groupby('sid')['rating'].mean() - global_mean\n",
    "    \n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    df_norm = df.copy()\n",
    "    \n",
    "    # Normalize ratings by user bias\n",
    "    def normalize_rating(row):\n",
    "        user_id = row['sid']\n",
    "        return row['rating'] - user_biases.get(user_id, 0)\n",
    "    \n",
    "    df_norm['rating'] = df_norm.apply(normalize_rating, axis=1)\n",
    "    \n",
    "    return df_norm, user_biases, global_mean\n",
    "\n",
    "# Apply preprocessing\n",
    "train_df_norm, user_biases, global_mean = preprocess_data(train_df)\n",
    "valid_df_norm = valid_df.copy()\n",
    "valid_df_norm['rating'] = valid_df_norm.apply(\n",
    "    lambda row: row['rating'] - user_biases.get(row['sid'], 0), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Determine number of users and items\n",
    "num_users = train_df['sid'].max() + 1\n",
    "num_items = train_df['pid'].max() + 1\n",
    "print(f\"Num users: {num_users}, Num items: {num_items}\")\n",
    "\n",
    "# Prepare data loader with normalized data\n",
    "train_loader = DataLoader(\n",
    "    RatingDataset(train_df_norm), \n",
    "    batch_size=256, \n",
    "    shuffle=True, \n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7e7f8e",
   "metadata": {},
   "source": [
    "## Call the train_classic_ncf Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28b5370e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Training GMF model...\n",
      "Epoch 01 — Train RMSE: 2.9695, Valid RMSE: 2.9711, LR: 0.001000\n",
      "Epoch 02 — Train RMSE: 2.9695, Valid RMSE: 2.9711, LR: 0.001000\n",
      "Epoch 03 — Train RMSE: 2.9695, Valid RMSE: 2.9711, LR: 0.001000\n",
      "Epoch 04 — Train RMSE: 2.9695, Valid RMSE: 2.9711, LR: 0.001000\n",
      "Early stopping triggered after 4 epochs\n",
      "\n",
      "Best Val RMSE: 2.9711\n",
      "\n",
      "Step 2: Training MLP model...\n",
      "Epoch 01 — Train RMSE: 0.8912, Valid RMSE: 0.9037, LR: 0.001000\n",
      "Epoch 02 — Train RMSE: 0.8762, Valid RMSE: 0.8918, LR: 0.001000\n",
      "Epoch 03 — Train RMSE: 0.8690, Valid RMSE: 0.8871, LR: 0.001000\n",
      "Epoch 04 — Train RMSE: 0.8545, Valid RMSE: 0.8791, LR: 0.001000\n",
      "Epoch 05 — Train RMSE: 0.8445, Valid RMSE: 0.8747, LR: 0.001000\n",
      "Epoch 06 — Train RMSE: 0.8386, Valid RMSE: 0.8731, LR: 0.001000\n",
      "Epoch 07 — Train RMSE: 0.8326, Valid RMSE: 0.8715, LR: 0.001000\n",
      "Epoch 08 — Train RMSE: 0.8283, Valid RMSE: 0.8701, LR: 0.001000\n",
      "Epoch 09 — Train RMSE: 0.8232, Valid RMSE: 0.8693, LR: 0.001000\n",
      "Epoch 10 — Train RMSE: 0.8178, Valid RMSE: 0.8688, LR: 0.001000\n",
      "Epoch 11 — Train RMSE: 0.8141, Valid RMSE: 0.8686, LR: 0.001000\n",
      "Epoch 12 — Train RMSE: 0.8087, Valid RMSE: 0.8685, LR: 0.001000\n",
      "Epoch 13 — Train RMSE: 0.8028, Valid RMSE: 0.8686, LR: 0.001000\n",
      "Epoch 14 — Train RMSE: 0.8008, Valid RMSE: 0.8679, LR: 0.001000\n",
      "Epoch 15 — Train RMSE: 0.7957, Valid RMSE: 0.8682, LR: 0.001000\n",
      "Epoch 16 — Train RMSE: 0.7953, Valid RMSE: 0.8673, LR: 0.001000\n",
      "Epoch 17 — Train RMSE: 0.7902, Valid RMSE: 0.8682, LR: 0.001000\n",
      "Epoch 18 — Train RMSE: 0.7853, Valid RMSE: 0.8686, LR: 0.001000\n",
      "Epoch 19 — Train RMSE: 0.7796, Valid RMSE: 0.8711, LR: 0.001000\n",
      "Early stopping triggered after 19 epochs\n",
      "\n",
      "Best Val RMSE: 0.8673\n",
      "\n",
      "Step 3: Fine-tuning combined model...\n",
      "Testing alpha = 0.3\n",
      "Epoch 01 — Train RMSE: 0.7857, Valid RMSE: 0.8749, LR: 0.000500\n",
      "Epoch 02 — Train RMSE: 0.7796, Valid RMSE: 0.8736, LR: 0.000500\n",
      "Epoch 03 — Train RMSE: 0.7776, Valid RMSE: 0.8729, LR: 0.000500\n",
      "Epoch 04 — Train RMSE: 0.7764, Valid RMSE: 0.8727, LR: 0.000500\n",
      "Epoch 05 — Train RMSE: 0.7744, Valid RMSE: 0.8740, LR: 0.000500\n",
      "Epoch 06 — Train RMSE: 0.7754, Valid RMSE: 0.8723, LR: 0.000500\n",
      "Epoch 07 — Train RMSE: 0.7724, Valid RMSE: 0.8752, LR: 0.000500\n",
      "Epoch 08 — Train RMSE: 0.7756, Valid RMSE: 0.8716, LR: 0.000500\n",
      "Epoch 09 — Train RMSE: 0.7736, Valid RMSE: 0.8732, LR: 0.000500\n",
      "Epoch 10 — Train RMSE: 0.7723, Valid RMSE: 0.8753, LR: 0.000500\n",
      "\n",
      "Best Val RMSE: 0.8716\n",
      "Testing alpha = 0.5\n",
      "Epoch 01 — Train RMSE: 0.7740, Valid RMSE: 0.8734, LR: 0.000500\n",
      "Epoch 02 — Train RMSE: 0.7734, Valid RMSE: 0.8735, LR: 0.000500\n",
      "Epoch 03 — Train RMSE: 0.7724, Valid RMSE: 0.8742, LR: 0.000500\n",
      "Epoch 04 — Train RMSE: 0.7728, Valid RMSE: 0.8739, LR: 0.000500\n",
      "Early stopping triggered after 4 epochs\n",
      "\n",
      "Best Val RMSE: 0.8734\n",
      "Testing alpha = 0.7\n",
      "Epoch 01 — Train RMSE: 0.7751, Valid RMSE: 0.8723, LR: 0.000500\n",
      "Epoch 02 — Train RMSE: 0.7739, Valid RMSE: 0.8738, LR: 0.000500\n",
      "Epoch 03 — Train RMSE: 0.7742, Valid RMSE: 0.8728, LR: 0.000500\n",
      "Epoch 04 — Train RMSE: 0.7745, Valid RMSE: 0.8726, LR: 0.000500\n",
      "Early stopping triggered after 4 epochs\n",
      "\n",
      "Best Val RMSE: 0.8723\n",
      "\n",
      "Final model with learnable alpha...\n",
      "Epoch 01 — Train RMSE: 0.7728, Valid RMSE: 0.8732, LR: 0.000100\n",
      "Epoch 02 — Train RMSE: 0.7742, Valid RMSE: 0.8718, LR: 0.000100\n",
      "Epoch 03 — Train RMSE: 0.7721, Valid RMSE: 0.8740, LR: 0.000100\n",
      "Epoch 04 — Train RMSE: 0.7712, Valid RMSE: 0.8747, LR: 0.000100\n",
      "Epoch 05 — Train RMSE: 0.7717, Valid RMSE: 0.8744, LR: 0.000100\n",
      "Epoch 06 — Train RMSE: 0.7715, Valid RMSE: 0.8746, LR: 0.000050\n",
      "Epoch 07 — Train RMSE: 0.7714, Valid RMSE: 0.8750, LR: 0.000050\n",
      "Early stopping triggered after 7 epochs\n",
      "\n",
      "Best Val RMSE: 0.8718\n",
      "Final fusion model RMSE: 0.8718\n"
     ]
    }
   ],
   "source": [
    "# Define loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Run the classic NeuMF training pipeline\n",
    "fusion_model, final_rmse = train_classic_ncf(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    train_loader=train_loader,\n",
    "    train_df=train_df_norm,\n",
    "    valid_df=valid_df_norm,\n",
    "    device=device,\n",
    "    criterion=criterion\n",
    ")\n",
    "\n",
    "print(f\"Final fusion model RMSE: {final_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af74b6ad",
   "metadata": {},
   "source": [
    "## Evaluate the Final Model\n",
    "\n",
    "Let's evaluate the final fusion model on the validation set and compare with the best RMSE value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd466cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "fusion_model.load_state_dict(torch.load('best_ncf.pth'))\n",
    "\n",
    "# Create prediction function\n",
    "def model_pred_fn(sids, pids):\n",
    "    fusion_model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = fusion_model(\n",
    "            torch.tensor(sids, dtype=torch.long).to(device),\n",
    "            torch.tensor(pids, dtype=torch.long).to(device)\n",
    "        ).cpu().numpy()\n",
    "    return preds\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_rmse = evaluate(valid_df_norm, model_pred_fn)\n",
    "print(f\"Validation RMSE (normalized ratings): {val_rmse:.4f}\")\n",
    "\n",
    "# Adjust predictions by adding back user biases\n",
    "def adjusted_pred_fn(sids, pids):\n",
    "    # Get base predictions\n",
    "    base_preds = model_pred_fn(sids, pids)\n",
    "    \n",
    "    # Add back user biases\n",
    "    adjusted_preds = np.array([\n",
    "        pred + user_biases.get(sid, 0) \n",
    "        for pred, sid in zip(base_preds, sids)\n",
    "    ])\n",
    "    \n",
    "    # Clip to valid rating range\n",
    "    return np.clip(adjusted_preds, 1, 5)\n",
    "\n",
    "# Evaluate on validation set with adjusted predictions\n",
    "val_rmse_adj = evaluate(valid_df, adjusted_pred_fn)\n",
    "print(f\"Validation RMSE (adjusted for user bias): {val_rmse_adj:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
