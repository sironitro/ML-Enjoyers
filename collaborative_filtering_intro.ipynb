{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b9bc283-1695-47ae-994e-fe742d0852d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Collaborative filtering project\n",
    "\n",
    "In this project, the task is to create a paper recommendation system. The system consists of 10,000 scientists and 1,000 papers. Scientists give ratings between 1â€“5 to the papers that they read. Since not all scientists have read every paper, we only have a limited amount of observations of these ratings. Additionally, each scientist has a wishlist of papers that they would like to read in the future. Your task is to fill in the missing observations using the provided rating and wishlist data, such that we can recommend papers to scientists that we expect them to rate highly.\n",
    "\n",
    "More specifically, there are three data sources:\n",
    " - `train_tbr.csv` containing wishlist data.\n",
    " - `train_ratings.csv` containing observed rating data.\n",
    " - `sample_submission.csv` containing (scientist, paper) pairs that have to be rated for the evaluation of your method.\n",
    "\n",
    "The data is available at `/cluster/courses/cil/collaborative_filtering/data` and an environment has been prepared for you at `/cluster/courses/cil/envs/collaborative_filtering`. You can activate the environment in your shell by running:\n",
    "```bash\n",
    "conda activate /cluster/courses/cil/envs/collaborative_filtering\n",
    "```\n",
    "If you wish to use notebooks on the cluster, you need to set the Environment path to `/cluster/courses/cil/envs/collaborative_filtering/bin` and load the `cuda/12.6` module.\n",
    "\n",
    "**Evaluation**: Your models are evaluated using the root mean-squared error (RMSE) metric. Your grade is determined by a linear interpolation between the easy (grade 4) and hard (grade 6) baselines.\n",
    "\n",
    "**Rules**: You are only allowed to use the data provided in `train_tbr.csv` and `train_ratings.csv` to make your predictions of `sample_submission.csv`. You are not allowed to use external data sources. But, you are allowed to use pre-trained models, as long as they are available publicly. Furthermore, no external API calls are allowed, except for downloading the weights of pre-trained models.\n",
    "\n",
    "**We will verify your code for plagiarism and using solutions from previous years.**\n",
    "\n",
    "[Link to Kaggle competition](https://www.kaggle.com/competitions/ethz-cil-collaborative-filtering-2025)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d799b9af-d742-4cac-a937-06102e652812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Callable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0063fd35-caac-4ced-b13e-b49cfb58d9a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Make sure that results are reproducible by using a seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73627bd-1106-4276-a498-32b44f1b5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65226f56-d281-45fd-bd93-54724ad47dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVDpp(nn.Module):\n",
    "    def __init__(self, num_scientists: int = 10000, num_papers: int = 10000, emb_dim: int = 8):\n",
    "        super().__init__()\n",
    "\n",
    "        # embeddings for scientists and papers\n",
    "        self.scientist_factors = nn.Embedding(num_scientists, emb_dim)\n",
    "        self.paper_factors = nn.Embedding(num_papers, emb_dim)\n",
    "        self.scientist_bias = nn.Embedding(num_scientists, 1)\n",
    "        self.paper_bias = nn.Embedding(num_papers, 1)\n",
    "\n",
    "        # global average rating - TODO: maybe come up with smth better\n",
    "        self.global_bias = nn.Parameter(torch.tensor([3.5]), requires_grad=False)\n",
    "\n",
    "        # init weights - TODO: not tuned rn\n",
    "        nn.init.normal_(self.scientist_factors.weight, std=0.1)\n",
    "        nn.init.normal_(self.paper_factors.weight, std=0.1)\n",
    "        nn.init.constant_(self.scientist_bias.weight, 0.0)\n",
    "        nn.init.constant_(self.paper_bias.weight, 0.0)\n",
    "\n",
    "    def forward(self, scientist_ids, paper_ids):\n",
    "        # latent factors and biases for current batch\n",
    "        scientist_embeddings = self.scientist_factors(scientist_ids)\n",
    "        paper_embeddings = self.paper_factors(paper_ids)\n",
    "        # squeeze to remove extra dim\n",
    "        scientist_biases = self.scientist_bias(scientist_ids).squeeze()\n",
    "        paper_biases = self.paper_bias(paper_ids).squeeze()\n",
    "    \n",
    "        # dot product for interaction\n",
    "        interaction = (scientist_embeddings * paper_embeddings).sum(dim=1)\n",
    "    \n",
    "        # predict ratings\n",
    "        predicted_ratings = interaction + scientist_biases + paper_biases + self.global_bias\n",
    "        return predicted_ratings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b5b6d6-37ed-40d1-b651-962c611a22c3",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93bc867-b2d9-4cf7-9bb8-ecb13c663eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = \"/cluster/courses/cil/collaborative_filtering/data\"\n",
    "DATA_DIR = \"./data\"\n",
    "\n",
    "\n",
    "def read_data_df() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Reads in data and splits it into training and validation sets with a 75/25 split.\"\"\"\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, \"train_ratings.csv\"))\n",
    "    implicit_df = pd.read_csv(os.path.join(DATA_DIR, \"train_tbr.csv\"))\n",
    "\n",
    "    # Split sid_pid into sid and pid columns\n",
    "    df[[\"sid\", \"pid\"]] = df[\"sid_pid\"].str.split(\"_\", expand=True)\n",
    "    df = df.drop(\"sid_pid\", axis=1)\n",
    "    df[\"sid\"] = df[\"sid\"].astype(int)\n",
    "    df[\"pid\"] = df[\"pid\"].astype(int)\n",
    "    \n",
    "    # Split into train and validation dataset\n",
    "    train_df, valid_df = train_test_split(df, test_size=0.25)\n",
    "    return train_df, valid_df, implicit_df\n",
    "\n",
    "\n",
    "def read_data_matrix(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Returns matrix view of the training data, where columns are scientists (sid) and\n",
    "    rows are papers (pid).\"\"\"\n",
    "\n",
    "    return df.pivot(index=\"sid\", columns=\"pid\", values=\"rating\").values\n",
    "\n",
    "\n",
    "def evaluate(valid_df: pd.DataFrame, pred_fn: Callable[[np.ndarray, np.ndarray], np.ndarray]) -> float:\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        valid_df: Validation data, returned from read_data_df for example.\n",
    "        pred_fn: Function that takes in arrays of sid and pid and outputs their rating predictions.\n",
    "\n",
    "    Outputs: Validation RMSE\n",
    "    \"\"\"\n",
    "    \n",
    "    preds = pred_fn(valid_df[\"sid\"].values, valid_df[\"pid\"].values)\n",
    "    return root_mean_squared_error(valid_df[\"rating\"].values, preds)\n",
    "\n",
    "\n",
    "def make_submission(pred_fn: Callable[[np.ndarray, np.ndarray], np.ndarray], filename: os.PathLike):\n",
    "    \"\"\"Makes a submission CSV file that can be submitted to kaggle.\n",
    "\n",
    "    Inputs:\n",
    "        pred_fn: Function that takes in arrays of sid and pid and outputs a score.\n",
    "        filename: File to save the submission to.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\n",
    "\n",
    "    # Get sids and pids\n",
    "    sid_pid = df[\"sid_pid\"].str.split(\"_\", expand=True)\n",
    "    sids = sid_pid[0]\n",
    "    pids = sid_pid[1]\n",
    "    sids = sids.astype(int).values\n",
    "    pids = pids.astype(int).values\n",
    "    \n",
    "    df[\"rating\"] = pred_fn(sids, pids)\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deb53ec-a5aa-408c-b6a5-118ffe14c035",
   "metadata": {},
   "source": [
    "## Singular value decomposition\n",
    "\n",
    "For the first method in this introduction, we will make use of the singular value decomposition (SVD) to construct the optimal rank-$k$ approximation (when measuring the Frobenius norm as error), according to the Eckart-Young theorem. Since the matrix needs to be fully observed in order to make use of SVD, we need to impute the missing values. In this case, we impute values with $3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3495d53a-ec1e-4692-a19b-6d8aa5fcf88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_values(mat: np.ndarray) -> np.ndarray:\n",
    "    return np.nan_to_num(mat, nan=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ecda7-3e44-4d99-894d-6927a12fe54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df, implicit_df = read_data_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5637bee3-2b0c-425e-b6b1-e13547d5ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model (10k scientists, 1k papers, 32-dimensional embeddings) and optimizer\n",
    "#model = EmbeddingDotProductModel(10_000, 1_000, 32).to(device)\n",
    "#optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "model = SVDpp().to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=6e-4, weight_decay=3e-5) # global on = \n",
    "# optim = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=3e-5) # global on = 0856\n",
    "# optim = torch.optim.Adam(model.parameters(), lr=6e-4, weight_decay=3e-5) + global off = 0.867\n",
    "#optim = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e866a9d-d5c6-40f1-b27f-d934eb6a5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(df: pd.DataFrame) -> torch.utils.data.Dataset:\n",
    "    \"\"\"Conversion from pandas data frame to torch dataset.\"\"\"\n",
    "    \n",
    "    sids = torch.from_numpy(df[\"sid\"].to_numpy())\n",
    "    pids = torch.from_numpy(df[\"pid\"].to_numpy())\n",
    "    ratings = torch.from_numpy(df[\"rating\"].to_numpy()).float()\n",
    "    return torch.utils.data.TensorDataset(sids, pids, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05764b4-5103-40fa-8910-3d84ea28a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(train_df)\n",
    "valid_dataset = get_dataset(valid_df)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8240462-5fc0-4c51-8e84-1082da8bf295",
   "metadata": {},
   "source": [
    "Training loop, which we run for 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085034ab-cb5a-444a-bcf4-a505cfd17e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "NUM_EPOCHS = 20 \n",
    "best_rmse = float(\"inf\")\n",
    "patience = 2\n",
    "epochs_no_improve = 0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Train model for an epoch\n",
    "    total_loss = 0.0\n",
    "    total_data = 0\n",
    "    model.train()\n",
    "    for sid, pid, ratings in train_loader:\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        pred = model(sid, pid)\n",
    "        loss = F.mse_loss(pred, ratings)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        total_data += len(sid)\n",
    "        total_loss += len(sid) * loss.item()\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    total_val_mse = 0.0\n",
    "    total_val_data = 0\n",
    "    model.eval()\n",
    "    for sid, pid, ratings in valid_loader:\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        pred = model(sid, pid).clamp(1, 5)\n",
    "        mse = F.mse_loss(pred, ratings)\n",
    "\n",
    "        total_val_data += len(sid)\n",
    "        total_val_mse += len(sid) * mse.item()\n",
    "\n",
    "    val_rmse = (total_val_mse / total_val_data) ** 0.5\n",
    "    train_loss = total_loss / total_data\n",
    "    print(f\"[Epoch {epoch+1}] Train loss={train_loss:.3f}, Valid RMSE={val_rmse:.3f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_rmse < best_rmse:\n",
    "        best_rmse = val_rmse\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Stopped early at epoch {epoch+1}. Best RMSE: {best_rmse:.4f}\")\n",
    "        break\n",
    "\n",
    "# load best model back\n",
    "model.load_state_dict(best_model_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73bec67-2ee0-4683-beb1-a102dac072d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fn = lambda sids, pids: model(torch.from_numpy(sids).to(device), torch.from_numpy(pids).to(device)).clamp(1, 5).cpu().numpy()\n",
    "\n",
    "# Evaluate on validation data\n",
    "with torch.no_grad():\n",
    "    val_score = evaluate(valid_df, pred_fn)\n",
    "\n",
    "print(f\"Validation RMSE: {val_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f42b995-2e08-4cfc-90aa-1b59a7e9fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    make_submission(pred_fn, \"learned_embedding_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeae800-f6d7-4182-9b7e-aa080e92d87e",
   "metadata": {},
   "source": [
    "## Outlook\n",
    "\n",
    "To further improve the score, students can make use of the information in `train_tbr.csv`, which contains the papers that scientists want to read. Furthermore, students can look into more modern collaborative filtering methods and techniques.\n",
    "\n",
    "Have fun :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7bad8f",
   "metadata": {},
   "source": [
    "## BFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc25ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6da73fc1",
   "metadata": {},
   "source": [
    "## BFM (explicit as implicit + implicit dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc27580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "import myfm\n",
    "from myfm import RelationBlock\n",
    "from scipy import sparse as sps\n",
    "\n",
    "\n",
    "FEATURE_COLUMNS = ['sid', 'pid']\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "X_train = ohe.fit_transform(train_df[FEATURE_COLUMNS])\n",
    "X_test = ohe.transform(valid_df[FEATURE_COLUMNS])\n",
    "\n",
    "# index \"0\" is reserved for unknown ids.\n",
    "scientist_to_index = defaultdict(lambda : 0, { sid: i+1 for i,sid in enumerate(np.unique(train_df.sid)) })\n",
    "paper_to_index = defaultdict(lambda: 0, { pid: i+1 for i,pid in enumerate(np.unique(train_df.pid))})\n",
    "SCIENTIST_ID_SIZE = len(scientist_to_index) + 1\n",
    "PAPER_ID_SIZE = len(paper_to_index) + 1\n",
    "\n",
    "paper_vs_read = dict()\n",
    "scientist_vs_read = dict()\n",
    "for row in train_df.itertuples():\n",
    "    sid = row.sid\n",
    "    pid = row.pid\n",
    "    paper_vs_read.setdefault(pid, list()).append(sid)\n",
    "    scientist_vs_read.setdefault(sid, list()).append(pid)\n",
    "    \n",
    "for row in implicit_df.itertuples():\n",
    "    sid = row.sid\n",
    "    pid = row.pid\n",
    "    paper_vs_read.setdefault(pid, list()).append(sid)\n",
    "    scientist_vs_read.setdefault(sid, list()).append(pid)\n",
    "    \n",
    "    \n",
    "    \n",
    "def augment_scientist_id(scientist_ids):\n",
    "    Xs = []\n",
    "    X_sid = sps.lil_matrix((len(scientist_ids), SCIENTIST_ID_SIZE))\n",
    "    for index, scientist_id in enumerate(scientist_ids):\n",
    "        X_sid[index, scientist_to_index[scientist_id]] = 1\n",
    "    Xs.append(X_sid)\n",
    "    X_is = sps.lil_matrix((len(scientist_ids), PAPER_ID_SIZE))\n",
    "    for index, scientist_id in enumerate(scientist_ids):\n",
    "        read_papers = scientist_vs_read.get(scientist_id, [])\n",
    "        normalizer = 1 / max(len(read_papers), 1) ** 0.5\n",
    "        for sid in read_papers:\n",
    "            X_is[index, paper_to_index[sid]] = normalizer\n",
    "    Xs.append(X_is)\n",
    "    return sps.hstack(Xs, format='csr')\n",
    "            \n",
    "            \n",
    "def augment_paper_id(paper_ids):\n",
    "    Xs = []\n",
    "    X_paper = sps.lil_matrix((len(paper_ids), PAPER_ID_SIZE))\n",
    "    for index, paper_id in enumerate(paper_ids):\n",
    "        X_paper[index, paper_to_index[paper_id]] = 1\n",
    "    Xs.append(X_paper)\n",
    "    X_ip = sps.lil_matrix((len(paper_ids), SCIENTIST_ID_SIZE))\n",
    "    for index, paper_id in enumerate(paper_ids):\n",
    "        read_scientists = paper_vs_read.get(paper_id, [])\n",
    "        normalizer = 1 / max(len(read_scientists), 1) ** 0.5\n",
    "        for sid in read_scientists:\n",
    "            X_ip[index, scientist_to_index[sid]] = normalizer\n",
    "    Xs.append(X_ip)\n",
    "    return sps.hstack(Xs, format='csr')\n",
    "\n",
    "\n",
    "\n",
    "train_sid_unique, train_sid_index = np.unique(train_df.sid, return_inverse=True)\n",
    "train_pid_unique, train_pid_index = np.unique(train_df.pid, return_inverse=True)\n",
    "scientist_data_train = augment_scientist_id(train_sid_unique)\n",
    "paper_data_train = augment_paper_id(train_pid_unique)\n",
    "\n",
    "test_sid_unique, test_sid_index = np.unique(valid_df.sid, return_inverse=True)\n",
    "test_pid_unique, test_pid_index = np.unique(valid_df.pid, return_inverse=True)\n",
    "scientist_data_test = augment_scientist_id(test_sid_unique)\n",
    "paper_data_test = augment_paper_id(test_pid_unique)\n",
    "\n",
    "\n",
    "block_scientist_train = RelationBlock(train_sid_index, scientist_data_train)\n",
    "block_paper_train = RelationBlock(train_pid_index, paper_data_train)\n",
    "block_scientist_test = RelationBlock(test_sid_index, scientist_data_test)\n",
    "block_paper_test = RelationBlock(test_pid_index, paper_data_test)\n",
    "\n",
    "\n",
    "fm_rb = myfm.MyFMRegressor(rank=32).fit(\n",
    "    X_train,\n",
    "    y = train_df.rating,\n",
    "    X_rel=[block_scientist_train, block_paper_train],\n",
    "    n_iter=300, n_kept_samples=300\n",
    ")\n",
    "\n",
    "\n",
    "def pred_fn(sids: np.ndarray, pids: np.ndarray) -> np.ndarray:\n",
    "    # Create a DataFrame to handle the data consistently\n",
    "    pred_df = pd.DataFrame({'sid': sids, 'pid': pids})\n",
    "    \n",
    "    # Transform the direct features\n",
    "    X = ohe.transform(pred_df[FEATURE_COLUMNS])\n",
    "    \n",
    "    # Process unique scientist and paper IDs for relational blocks\n",
    "    pred_sid_unique, pred_sid_index = np.unique(pred_df.sid, return_inverse=True)\n",
    "    pred_pid_unique, pred_pid_index = np.unique(pred_df.pmake_submission(pred_fn, \"learned_myfm_submission.csv\"), return_inverse=True)\n",
    "    \n",
    "    # Generate augmented data for scientists and papers\n",
    "    scientist_data_pred = augment_scientist_id(pred_sid_unique)\n",
    "    paper_data_pred = augment_paper_id(pred_pid_unique)\n",
    "    \n",
    "    # Create the relational blocks\n",
    "    block_scientist_pred = RelationBlock(pred_sid_index, scientist_data_pred)\n",
    "    block_paper_pred = RelationBlock(pred_pid_index, paper_data_pred)\n",
    "    \n",
    "    # Make the prediction with relational blocks\n",
    "    return fm_rb.predict(X, X_rel=[block_scientist_pred, block_paper_pred])\n",
    "\n",
    "\n",
    "print(evaluate(valid_df, pred_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be2c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder\n",
    "from sklearn import metrics\n",
    "import myfm\n",
    "\n",
    "FEATURE_COLUMNS = ['sid', 'pid']\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "X_train = ohe.fit_transform(train_df[FEATURE_COLUMNS])\n",
    "X_test = ohe.transform(valid_df[FEATURE_COLUMNS])\n",
    "y_train = train_df.rating.values\n",
    "y_test = valid_df.rating.values\n",
    "\n",
    "print([len(group) for group in ohe.categories_])\n",
    "\n",
    "\n",
    "fm = myfm.MyFMOrderedProbit(\n",
    "    rank=32, random_seed=42,\n",
    ")\n",
    "fm.fit(\n",
    "    X_train, y_train - 1, n_iter=300, n_kept_samples=300,\n",
    "    group_shapes=[len(group) for group in ohe.categories_]\n",
    ")\n",
    "\n",
    "p_ordinal = fm.predict_proba(X_test)\n",
    "\n",
    "expected_rating = p_ordinal.dot(np.arange(1, 6))\n",
    "rmse = ((y_test - expected_rating) ** 2).mean() ** .5\n",
    "mae = np.abs(y_test - expected_rating).mean()\n",
    "print(f'rmse={rmse}, mae={mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd03b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b9da87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(pred_fn, \"learned_myfm_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53ca39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ab249",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFWithImplicitContrastiveLoss(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(MFWithImplicitContrastiveLoss, self).__init__()\n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim)\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        user_emb = self.user_embeddings(user)\n",
    "        item_emb = self.item_embeddings(item)\n",
    "        return (user_emb * item_emb).sum(dim=1)  # Predicted rating\n",
    "    \n",
    "    def contrastive_loss(self, user, pos_item, neg_item):\n",
    "        user_emb = self.user_embeddings(user)\n",
    "        pos_item_emb = self.item_embeddings(pos_item)\n",
    "        neg_item_emb = self.item_embeddings(neg_item)\n",
    "        \n",
    "        # Calculate positive similarity\n",
    "        pos_sim = (user_emb * pos_item_emb).sum(dim=1)  # (batch_size)\n",
    "        \n",
    "        # Calculate negative similarities for each negative sample (batch_size, num_negatives)\n",
    "        neg_sim = (user_emb.unsqueeze(1) * neg_item_emb).sum(dim=2)  # (batch_size, num_negatives)\n",
    "        \n",
    "        # Calculate contrastive loss (margin-based)\n",
    "        margin = 1.0\n",
    "        loss = torch.clamp(margin - pos_sim.unsqueeze(1) + neg_sim, min=0)  # (batch_size, num_negatives)\n",
    "        \n",
    "        return loss.mean()  # Mean across all samples and negative items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df213945",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeContrastiveDataset(Dataset):\n",
    "    def __init__(self, df, implicit_df, negative_samples=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: DataFrame with explicit ratings (user-item)\n",
    "            implicit_df: DataFrame with implicit feedback (user-item, binary values)\n",
    "            negative_samples: Number of negative samples per user-item pair\n",
    "        \"\"\"\n",
    "        self.ratings = df.reset_index(drop=True)\n",
    "        self.implicit = implicit_df.reset_index(drop=True)\n",
    "        self.num_papers = df['pid'].nunique()\n",
    "        self.negative_samples = negative_samples\n",
    "\n",
    "        # Combine explicit and implicit interactions for negative sampling\n",
    "        self.scientist_interactions = (\n",
    "            pd.concat([self.ratings[['sid', 'pid']], self.implicit], ignore_index=True)\n",
    "            .groupby('sid')['pid']\n",
    "            .apply(set)\n",
    "            .to_dict()\n",
    "        )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)  # One entry per explicit rating\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Fetch the row from the ratings DataFrame\n",
    "        row = self.ratings.iloc[idx]  # This is a pandas Series, not a tuple\n",
    "        \n",
    "        scientist = int(row['sid'])\n",
    "        pos_paper = int(row['pid'])\n",
    "        rating = float(row['rating'])\n",
    "        \n",
    "        # Positive pair from implicit feedback: sample one\n",
    "        implicit_scientist_rows = self.implicit[self.implicit['sid'] == scientist]\n",
    "        if not implicit_scientist_rows.empty:\n",
    "            pos_implicit_paper = int(implicit_scientist_rows.sample(1)['pid'].values[0])\n",
    "        else:\n",
    "            pos_implicit_paper = pos_paper  # fallback to same as rating\n",
    "        \n",
    "        # Sample negatives\n",
    "        negatives = []\n",
    "        interacted = self.scientist_interactions.get(scientist, set())\n",
    "        while len(negatives) < self.negative_samples:\n",
    "            neg_paper = np.random.randint(self.num_papers)\n",
    "            if neg_paper not in interacted:\n",
    "                negatives.append(neg_paper)\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(scientist, dtype=torch.long),\n",
    "            torch.tensor(pos_paper, dtype=torch.long),\n",
    "            torch.tensor(pos_implicit_paper, dtype=torch.long),\n",
    "            torch.tensor(negatives, dtype=torch.long),\n",
    "            torch.tensor(rating, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingsOnlyDataset(Dataset):\n",
    "    def __init__(self, ratings_df):\n",
    "        self.ratings = ratings_df.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.ratings.iloc[idx]\n",
    "        sid = int(row['sid'])\n",
    "        pid = int(row['pid'])\n",
    "        rating = float(row['rating'])\n",
    "\n",
    "        return (\n",
    "            torch.tensor(sid, dtype=torch.long),\n",
    "            torch.tensor(pid, dtype=torch.long),\n",
    "            torch.tensor(rating, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b0548",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CollaborativeContrastiveDataset(train_df, implicit_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_dataset = RatingsOnlyDataset(valid_df)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "model = MFWithImplicitContrastiveLoss(10000, 10000, 32).to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=6e-4, weight_decay=3e-5)\n",
    "criterion = nn.MSELoss()\n",
    "    \n",
    "NUM_EPOCHS = 20\n",
    "best_rmse = float(\"inf\")\n",
    "patience = 2\n",
    "epochs_no_improve = 0\n",
    "best_model_state = None    \n",
    "    \n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Train model for an epoch\n",
    "    total_loss = 0.0\n",
    "    total_data = 0\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        sid, pos_pid, pos_implicit_paper, neg_papers, rating = batch\n",
    "        sid = sid.to(device)\n",
    "        pos_pid = pos_pid.to(device) \n",
    "        pos_implicit_paper = pos_implicit_paper.to(device)\n",
    "        neg_papers = neg_papers.to(device)\n",
    "        rating = rating.to(device)\n",
    "        \n",
    "        predicted_rating = model(sid, pos_pid)\n",
    "        \n",
    "        mse_loss = F.mse_loss(predicted_rating, rating)\n",
    "        loss_contrastive = model.contrastive_loss(sid, pos_implicit_paper, neg_papers)\n",
    "\n",
    "        loss = 0.7 * mse_loss + 0.3 * loss_contrastive\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_data += len(sid)\n",
    "        total_loss += len(sid) * loss.item()\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    total_val_mse = 0.0\n",
    "    total_val_data = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for sid, pid, rating in valid_loader:\n",
    "            sid = sid.to(device)\n",
    "            pid = pid.to(device)\n",
    "            rating = rating.to(device)\n",
    "\n",
    "            # Forward pass: predict rating\n",
    "            predicted_rating = model(sid, pid)\n",
    "\n",
    "            # MSE loss for regression\n",
    "            mse_loss = F.mse_loss(predicted_rating, rating, reduction='sum')\n",
    "\n",
    "            total_val_mse += mse_loss.item()\n",
    "            total_val_data += len(sid)\n",
    "\n",
    "    val_rmse = (total_val_mse / total_val_data) ** 0.5\n",
    "    train_loss = total_loss / total_data\n",
    "    print(f\"[Epoch {epoch+1}] Train loss={train_loss:.3f}, Valid RMSE={val_rmse:.3f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_rmse < best_rmse:\n",
    "        best_rmse = val_rmse\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Stopped early at epoch {epoch+1}. Best RMSE: {best_rmse:.4f}\")\n",
    "        break\n",
    "\n",
    "# load best model back\n",
    "model.load_state_dict(best_model_state)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dec4b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from recommenders.models.ncf.ncf_singlenode import NCF\n",
    "# from recommenders.models.ncf.dataset import Dataset as NCFDataset\n",
    "\n",
    "\n",
    "# train_file = DATA_DIR + \"/train.csv\"\n",
    "# test_file = DATA_DIR + \"/test.csv\"\n",
    "# train_df.to_csv(train_file, index=False)\n",
    "# valid_df.to_csv(test_file, index=False)\n",
    "\n",
    "\n",
    "# train_dataset = NCFDataset(train_file, col_user='sid', col_item='pid', col_rating='rating')\n",
    "# valid_dataset = NCFDataset(test_file, col_user='sid', col_item='pid', col_rating='rating')\n",
    "\n",
    "\n",
    "# ncf_model = NCF(\n",
    "#     n_users=train_df['sid'].nunique(),\n",
    "#     n_items=train_df['pid'].nunique(),\n",
    "#     model_type=\"NeuMF\",  # Other options: GMF, MLP\n",
    "#     n_factors=32,\n",
    "#     layer_sizes=[16, 8],\n",
    "#     learning_rate=0.001,\n",
    "#     batch_size=64,\n",
    "#     n_epochs=10,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# # Fit the model\n",
    "# ncf_model.fit(train_df)\n",
    "\n",
    "# user_item_pairs = valid_df[['userID', 'itemID']]\n",
    "# predictions = ncf_model.predict(user_item_pairs)\n",
    "\n",
    "\n",
    "# rmse_score = rmse(valid_df['rating'], predictions)\n",
    "# print(f\"RMSE: {rmse_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
